{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-12T00:58:47.060104Z",
     "start_time": "2024-11-12T00:58:45.287174Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer, pipeline\n",
    "import torch\n",
    "from transformers import pipeline"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T00:58:47.544781Z",
     "start_time": "2024-11-12T00:58:47.066826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_id = \"google/gemma-2b\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ],
   "id": "f3820930df47764f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T03:08:45.854160Z",
     "start_time": "2024-11-09T03:08:45.850702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test = tokenizer(\"Hi\", return_tensors=\"pt\")\n",
    "print(test)"
   ],
   "id": "40c0fe14e5cdcebf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   2, 2151]]), 'attention_mask': tensor([[1, 1]])}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T07:58:28.697969Z",
     "start_time": "2024-08-19T07:58:28.694553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test = tokenizer(\"Hello, Jerry is a student of the university of Saarland. He studies Computer science.\", return_tensors=\"pt\")\n",
    "print(test)\n"
   ],
   "id": "5ec767e8754bae71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[     2,   4521, 235269,  31656,    603,    476,   5913,    576,    573,\n",
      "          13435,    576,  96808,   1445, 235265,   1315,   6438,  15963,   8042,\n",
      "         235265]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T03:19:15.822295Z",
     "start_time": "2024-11-09T03:19:15.276607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Using the pipeline !\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"In this course, we will teach you how to\")"
   ],
   "id": "84d9b5d23262bccb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9993911981582642}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T08:12:16.633519Z",
     "start_time": "2024-08-19T08:04:40.586238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# getting the embeddings\n",
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(model_id)\n",
    "with torch.no_grad():  # Disable gradient calculations to save memory\n",
    "    outputs = model(**test)\n",
    "\n"
   ],
   "id": "301e1bd6784d2382",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c23cfaba7f7c42ff96aabd2d4f11e127"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a324db5b5fbb44cfaf11c9af67f12a27"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15b9eb32c8504e0c86249dd7ccabf590"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "162af671b72f4958b7173e09e14224b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ede9c0970ae54d1eb5d4148fa93b0f20"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2102082f740248128c2f47ef23772fd2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T08:43:02.045474Z",
     "start_time": "2024-08-19T08:43:02.040959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# outputs.last_hidden_state contains the embeddings for each token\n",
    "embeddings = outputs.last_hidden_state\n",
    "embeddings[0]"
   ],
   "id": "575ed9468d503a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3116, -0.6693,  0.1596,  ..., -0.1884,  0.2425,  0.1245],\n",
       "        [-0.5034,  0.0232, -0.7929,  ...,  0.0115,  0.9474, -0.2379],\n",
       "        [-0.2977,  0.4621,  0.2103,  ...,  0.5183,  1.1501,  0.0036],\n",
       "        ...,\n",
       "        [ 0.6380,  0.2522, -0.1038,  ..., -0.4299,  1.2579,  0.3517],\n",
       "        [-0.3215, -0.1665,  0.0510,  ..., -0.1017,  0.9959,  0.8404],\n",
       "        [-0.1254,  0.4106,  0.3781,  ...,  0.7781,  0.8971,  0.7292]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch import tensor\n",
    "\n",
    "example = \"Hello, I am a student of the university of Saarland. I study Computer science.\"\n",
    "output_example = \"the output\"\n",
    "\n",
    "model_input = tokenizer(example, max_length=8, padding=\"max_length\", truncation=True)\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    labels = tokenizer(output_example, max_length=8, padding=\"max_length\", truncation=True)\n",
    "\n",
    "model_input['labels'] = labels['input_ids']\n",
    "\n",
    "#print(tokenizer.convert_ids_to_tokens(model_input[\"labels\"]))\n",
    "#print(model_input)\n",
    "input = tensor(model_input['input_ids'])\n",
    "print(tokenizer.decode(model_input['input_ids']))\n",
    "print(type(tensor(model_input['input_ids'])))\n",
    "\n",
    "#print(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(example)))"
   ],
   "id": "347f85c073c1633a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### In the following cell, I will test the output of the tokenizer for the thesis model",
   "id": "6a071f2b79eeaf82"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T13:10:45.050216Z",
     "start_time": "2024-11-14T13:10:44.597411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### testing the tokenizer for the thesis model\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch import tensor\n",
    "\n",
    "model_id = \"google/gemma-2b\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ],
   "id": "fc8d83d95d07a010",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T13:11:53.415852Z",
     "start_time": "2024-11-14T13:11:53.412157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_function(examples):\n",
    "    instruction = \"Complete the following software model by finding the missing part: \"\n",
    "    inputs = [instruction + inp for inp in examples['input']]\n",
    "    targets = examples['output']\n",
    "    max_length = 2000\n",
    "    model_input = tokenizer(inputs, max_length=max_length, padding=\"max_length\", truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_length, padding=\"max_length\", truncation=True)\n",
    "\n",
    "    model_input['labels'] = labels['input_ids']\n",
    "    return model_input"
   ],
   "id": "69491c85ad77badc",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T13:11:55.538514Z",
     "start_time": "2024-11-14T13:11:55.127554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "#train_dataset_url = \"/Users/jerrytakou/University/Thesis/programming/thesis/datasets_for_fine_tuning/structural_removal_non_contiguous/processed_2000train.jsonl\"\n",
    "#test_dataset_url =\"/Users/jerrytakou/University/Thesis/programming/thesis/datasets_for_fine_tuning/structural_removal_non_contiguous/processed_2000processed_2000/test.jsonl\"\n",
    "validation_dataset_url =\"/Users/jerrytakou/University/Thesis/programming/thesis/datasets_for_fine_tuning/structural_removal_non_contiguous/processed_2000/validation.jsonl\"\n",
    "\n",
    "\n",
    "data_files = {\n",
    "    #'train': train_dataset_url,\n",
    "    #'test': test_dataset_url,\n",
    "    'validation': validation_dataset_url\n",
    "}\n",
    "\n",
    "dataset = load_dataset('json', data_files=data_files)\n",
    "validation_dataset = dataset['validation']"
   ],
   "id": "32d914914c5d8ab6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T13:11:57.432128Z",
     "start_time": "2024-11-14T13:11:57.215790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "validation_data = validation_dataset.map(tokenize_function, batched=True)\n",
    "input = tensor(validation_data['input_ids'])\n",
    "print(tokenizer.decode(input[0]))\n"
   ],
   "id": "b4f0a92e781c051c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/18 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ee82d611f814bffb5cb0b68bdf33f73"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><bos>Complete the following software model by finding the missing part: {\"directed\":true,\"nodes\":[{\"viewpoint\":null,\"visibility\":\"PUBLIC_LITERAL\",\"qualifiedName\":\"model\",\"name\":\"model\",\"id\":0,\"URI\":null,\"eClass\":\"Model\"},{\"isSingleExecution\":false,\"isReadOnly\":false,\"visibility\":\"PUBLIC_LITERAL\",\"qualifiedName\":\"model::Activity\",\"name\":\"Activity\",\"id\":2,\"isActive\":false,\"isReentrant\":true,\"isLeaf\":false,\"isAbstract\":false,\"isFinalSpecialization\":false,\"eClass\":\"Activity\"},{\"visibility\":\"PUBLIC_LITERAL\",\"qualifiedName\":\"ControlFlow\",\"name\":\"ControlFlow\",\"id\":4,\"isLeaf\":false,\"eClass\":\"ControlFlow\"},{\"visibility\":\"PUBLIC_LITERAL\",\"qualifiedName\":\"ControlFlow\",\"name\":\"ControlFlow\",\"id\":5,\"isLeaf\":false,\"eClass\":\"ControlFlow\"},{\"visibility\":\"PUBLIC_LITERAL\",\"qualifiedName\":\"ControlFlow\",\"name\":\"ControlFlow\",\"id\":6,\"isLeaf\":false,\"eClass\":\"ControlFlow\"},{\"visibility\":\"PUBLIC_LITERAL\",\"qualifiedName\":\"ControlFlow\",\"name\":\"ControlFlow\",\"id\":7,\"isLeaf\":false,\"eClass\":\"ControlFlow\"},{\"visibility\":\"PUBLIC_LITERAL\",\"qualifiedName\":\"InitialNode\",\"name\":\"InitialNode\",\"id\":8,\"isLeaf\":false,\"eClass\":\"InitialNode\"},{\"visibility\":\"PUBLIC_LITERAL\",\"qualifiedName\":\"ActivityFinalNode\",\"name\":\"ActivityFinalNode\",\"id\":9,\"isLeaf\":false,\"eClass\":\"ActivityFinalNode\"},{\"visibility\":\"PUBLIC_LITERAL\",\"qualifiedName\":\"DecisionNode\",\"name\":\"DecisionNode\",\"id\":12,\"isLeaf\":false,\"eClass\":\"DecisionNode\"},{\"visibility\":\"PUBLIC_LITERAL\",\"qualifiedName\":null,\"isLocallyReentrant\":false,\"name\":\"\",\"language\":[],\"id\":13,\"body\":[],\"isLeaf\":false,\"eClass\":\"OpaqueAction\"},{\"visibility\":\"PUBLIC_LITERAL\",\"qualifiedName\":\"ForkNode2\",\"name\":\"ForkNode2\",\"id\":14,\"isLeaf\":false,\"eClass\":\"ForkNode\"},{\"visibility\":\"PUBLIC_LITERAL\",\"qualifiedName\":\"DecisionNode2\",\"name\":\"DecisionNode2\",\"id\":15,\"isLeaf\":false,\"eClass\":\"DecisionNode\"},{\"visibility\":\"PUBLIC_LITERAL\",\"qualifiedName\":\"DecisionNode3\",\"name\":\"DecisionNode3\",\"id\":16,\"isLeaf\":false,\"eClass\":\"DecisionNode\"},{\"visibility\":\"PUBLIC_LITERAL\",\"qualifiedName\":\"OpaqueAction\",\"isLocallyReentrant\":false,\"name\":\"OpaqueAction\",\"language\":[],\"id\":17,\"body\":[],\"isLeaf\":false,\"eClass\":\"OpaqueAction\"},{\"visibility\":\"PUBLIC_LITERAL\",\"qualifiedName\":\"OpaqueAction2\",\"isLocallyReentrant\":false,\"name\":\"OpaqueAction2\",\"language\":[],\"id\":18,\"body\":[],\"isLeaf\":false,\"eClass\":\"OpaqueAction\"},{\"visibility\":\"PUBLIC_LITERAL\",\"qualifiedName\":null,\"name\":null,\"id\":20,\"value\":\"true\",\"eClass\":\"LiteralString\"},{\"visibility\":\"PUBLIC_LITERAL\",\"qualifiedName\":null,\"name\":null,\"id\":21,\"value\":\"true\",\"eClass\":\"LiteralString\"},{\"visibility\":\"PUBLIC_LITERAL\",\"qualifiedName\":null,\"name\":null,\"id\":22,\"value\":\"true\",\"eClass\":\"LiteralString\"},{\"visibility\":\"PUBLIC_LITERAL\",\"qualifiedName\":null,\"name\":null,\"id\":23,\"value\":\"true\",\"eClass\":\"LiteralString\"}],\"links\":[{\"source\":0,\"target\":2},{\"source\":2,\"target\":4},{\"source\":2,\"target\":5},{\"source\":2,\"target\":6},{\"source\":2,\"target\":7},{\"source\":2,\"target\":8},{\"source\":2,\"target\":9},{\"source\":2,\"target\":12},{\"source\":2,\"target\":13},{\"source\":2,\"target\":14},{\"source\":2,\"target\":15},{\"source\":2,\"target\":16},{\"source\":2,\"target\":17},{\"source\":2,\"target\":18},{\"source\":4,\"target\":2},{\"source\":4,\"target\":20},{\"source\":4,\"target\":15},{\"source\":4,\"target\":14},{\"source\":5,\"target\":2},{\"source\":5,\"target\":21},{\"source\":5,\"target\":16},{\"source\":5,\"target\":14},{\"source\":6,\"target\":2},{\"source\":6,\"target\":22},{\"source\":6,\"target\":17},{\"source\":6,\"target\":15},{\"source\":7,\"target\":2},{\"source\":7,\"target\":23},{\"source\":7,\"target\":18},{\"source\":7,\"target\":15},{\"source\":14,\"target\":4},{\"source\":14,\"target\":5},{\"source\":15,\"target\":4},{\"source\":15,\"target\":6},{\"source\":15,\"target\":7},{\"source\":16,\"target\":5},{\"source\":17,\"target\":6},{\"source\":18,\"target\":7}],\"multigraph\":true}\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### In the following cell, I want to see the output of the model when it receives the tokenized input",
   "id": "15451d4b44aa0151"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T12:10:25.845100Z",
     "start_time": "2024-11-12T12:10:25.454668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "sequences = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n",
    "\n",
    "tokens = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "output = model(**tokens)"
   ],
   "id": "a06f9099c017932a",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T12:11:02.467956Z",
     "start_time": "2024-11-12T12:11:02.464565Z"
    }
   },
   "cell_type": "code",
   "source": "print(output)",
   "id": "6cd4e93996a17757",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-1.5607,  1.6123],\n",
      "        [-3.6183,  3.9137]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
