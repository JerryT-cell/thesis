{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-21T06:19:16.902150Z",
     "start_time": "2024-11-21T06:19:15.431859Z"
    }
   },
   "source": [
    "import torch\n",
    "from prompt_toolkit.contrib.regular_languages.regex_parser import tokenize_regex\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " ### Running the model on a GPU",
   "id": "b1e2d643017d2be7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T06:19:42.451265Z",
     "start_time": "2024-11-21T06:19:42.448059Z"
    }
   },
   "cell_type": "code",
   "source": "checkpoint = \"google/gemma-2-2b-it\"  ",
   "id": "8998b14db01c4f24",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T06:27:25.956194Z",
     "start_time": "2024-11-21T06:19:43.515355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    checkpoint,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map =\"auto\",\n",
    "    attn_implementation=\"eager\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ],
   "id": "9032fe5f50d1192c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/838 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1cabd0db5934b678d25ffd9d7bd46c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\LLM\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--google--gemma-2-2b-it. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/24.2k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13418240093e41db8a61d1dc4ff9beba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9de4f2c006c34f4899d35e8db2d2c45d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1eae767cc0474faba072d9f6e75b4020"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/241M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f89b1e2793747728daa61e905cd9bd4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a25d59c616744cfbdd79cc5577a7256"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0cf2d7fe5f84bbc8223d0e341395469"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/47.0k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc2d1769e33c4599b1f1456118763cb1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4acf7e6d453940cdb49ef7ed3b50867f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ada788ae571642c1bc977b6ceb3458a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0cddae45b7d14f67bcb5cf010699ef1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Applying chat template",
   "id": "7a1cda242ab739f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:08:21.771826Z",
     "start_time": "2024-11-21T07:08:21.767327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test_data = dataset[\"test\"]\n",
    "instruction =\"You are a helpful programmer instruction\"\n",
    "\n",
    "messages = [\n",
    "            {\"role\": \"user\", \"content\": \"write a function that takes a list of integers and returns the sum of all the integers in the list in java.\"},\n",
    "    {\"role\": \"model\", \"content\": \"write a function that takes a list of integers and returns the sum of all the integers in the list in java.\"}     \n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "print(text)"
   ],
   "id": "2de07b950bda9410",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><start_of_turn>user\n",
      "write a function that takes a list of integers and returns the sum of all the integers in the list in java.<end_of_turn>\n",
      "<start_of_turn>model\n",
      "write a function that takes a list of integers and returns the sum of all the integers in the list in java.<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T06:38:15.913694Z",
     "start_time": "2024-11-21T06:38:15.907570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(\"cuda\")\n",
    "print(text)"
   ],
   "id": "96d2d3804f05b630",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     2,    106,   1645,    108,   4086,    476,   1411,    674,   5548,\n",
      "            476,   1889,    576,  45047,    578,   8753,    573,   2707,    576,\n",
      "            832,    573,  45047,    575,    573,   1889,    575,   1821, 235265,\n",
      "            107,    108,    106,   2516,    108]], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T06:38:42.530135Z",
     "start_time": "2024-11-21T06:38:26.649169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outputs = model.generate(input_ids=text, do_sample=True, max_new_tokens=200)\n",
    "print(tokenizer.decode(outputs[0]))"
   ],
   "id": "674e8cc221bd2fe5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><start_of_turn>user\n",
      "write a function that takes a list of integers and returns the sum of all the integers in the list in java.<end_of_turn>\n",
      "<start_of_turn>model\n",
      "```java\n",
      "import java.util.List;\n",
      "\n",
      "public class SumList {\n",
      "\n",
      "    public static int sum(List<Integer> numbers) {\n",
      "        int sum = 0;\n",
      "        for (Integer number : numbers) { \n",
      "            sum += number; \n",
      "        }\n",
      "        return sum;\n",
      "    }\n",
      "\n",
      "    public static void main(String[] args) {\n",
      "        List<Integer> numberList = List.of(1, 2, 3, 4, 5);\n",
      "        int totalSum = sum(numberList);\n",
      "\n",
      "        System.out.println(\"The sum of the numbers is: \" + totalSum);\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "* **Function Definition:**  \n",
      "    * `public static int sum(List<Integer> numbers)`: \n",
      "        * `public` means the method is accessible from other parts of your code.\n",
      "        * `static` means it's\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Without chat template",
   "id": "4032c123dd0d7ac7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:12:16.857412Z",
     "start_time": "2024-11-21T07:12:16.851193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input = \"Instruction : write a function that takes a list of integers and returns the sum of all the integers in the list in java. \\n Response:\"\n",
    "input_ids = tokenizer(input, return_tensors=\"pt\").to(\"cuda\")\n",
    "input_ids"
   ],
   "id": "7eb678022dce9e98",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[     2,  37854,    865,   5598,    476,   1411,    674,   5548,    476,\n",
       "           1889,    576,  45047,    578,   8753,    573,   2707,    576,    832,\n",
       "            573,  45047,    575,    573,   1889,    575,   1821, 235265, 235248,\n",
       "            108,  10567, 235292]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:12:30.685944Z",
     "start_time": "2024-11-21T07:12:18.024726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outputs = model.generate(input_ids=input_ids['input_ids'], do_sample=True, max_new_tokens=200)\n",
    "print(tokenizer.decode(outputs[0]))"
   ],
   "id": "901a87f658b83632",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>Instruction : write a function that takes a list of integers and returns the sum of all the integers in the list in java. \n",
      " Response: \n",
      " \n",
      " ```java\n",
      "public class Main {\n",
      "  public static int sumOfList(int[] list) {\n",
      "    int totalSum = 0;\n",
      "    for (int i = 0; i < list.length; i++) {\n",
      "      totalSum += list[i];\n",
      "    }\n",
      "    return totalSum;\n",
      "  }\n",
      "  \n",
      "  public static void main(String[] args) {\n",
      "    int[] numbers = {1, 2, 3, 4, 5};\n",
      "    System.out.println(sumOfList(numbers));\n",
      "  }\n",
      "}\n",
      "```\n",
      "  \n",
      " **The function `sumOfList` does the following:**\n",
      "\n",
      "1.  **Takes an integer array (list) as input using `int[] list`.**\n",
      "2.  **Initializes a variable `totalSum` to 0.** This variable will store the cumulative sum. \n",
      "3.  **Loops through the\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Inference for LLM for software Model Completion",
   "id": "7626e761723ec7d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from datasets import load_dataset",
   "id": "7526b2b2afb80921"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "checkpoint = \"D:\\\\LLM\\\\thesisPractical\\\\fine_tuned_models\\\\gemma\\\\results\\\\checkpoint-500\"",
   "id": "245023f3d3a6ba49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    checkpoint,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map =\"auto\",\n",
    "    attn_implementation=\"eager\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ],
   "id": "188046dd5b916e7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "org_path = \"D:\\LLM\\\\thesisPractical\\\\datasets\\\\structural_removal_non_contiguous\\\\processed_4000\"\n",
    "\n",
    "test_dataset_url = org_path + \"\\\\test.jsonl\"\n",
    "\n",
    "data_files = {\n",
    "    'test' : test_dataset_url\n",
    "}\n",
    "\n",
    "dataset = load_dataset('json', data_files=data_files)\n",
    "test_dataset = dataset['test']"
   ],
   "id": "d08c92d7902dfdb0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = test_dataset[0]['input']\n",
    "output = test_dataset[0]['output']\n",
    "print(data)"
   ],
   "id": "29a90bf61f1edcba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "input_ids = tokenizer(data, padding=True,return_tensors='pt', truncation=True, max_length=3500).to(\"cuda\")",
   "id": "bfb5f0ed39bb1ee7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "outputs = model.generate(**input_ids, max_length=3500)\n",
    "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(decoded_output)"
   ],
   "id": "a8fa58b6ebf033de"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
