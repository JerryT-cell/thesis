{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T01:47:14.941019Z",
     "start_time": "2024-07-14T01:47:02.826691Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -qU transformers",
   "id": "bb5319fd2ba184cf",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T01:47:15.818065Z",
     "start_time": "2024-07-14T01:47:15.813935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer,  DataCollatorForSeq2Seq)\n",
    "import torch\n",
    "from evaluate import load\n",
    "import numpy as np\n",
    "import matplotlib"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get Data",
   "id": "b7f5349c23da5dbb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T01:47:18.149132Z",
     "start_time": "2024-07-14T01:47:17.339570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_files = {\n",
    "    'train': 't5_datasets/train.jsonl',\n",
    "    'test': 't5_datasets/test.jsonl',\n",
    "    'validation': 't5_datasets/validation.jsonl'\n",
    "}\n",
    "\n",
    "dataset = load_dataset('json', data_files=data_files)\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n",
    "validation_dataset = dataset['validation']"
   ],
   "id": "383fcb3161e7942c",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T01:47:19.186716Z",
     "start_time": "2024-07-14T01:47:19.176655Z"
    }
   },
   "cell_type": "code",
   "source": "dataset",
   "id": "4e08e0c0cadcde22",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'output'],\n",
       "        num_rows: 3584\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input', 'output'],\n",
       "        num_rows: 768\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input', 'output'],\n",
       "        num_rows: 768\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get the token and the T5 model",
   "id": "a975af5c54a27cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T01:47:27.318673Z",
     "start_time": "2024-07-14T01:47:25.098770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = 'google-t5/t5-base'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ],
   "id": "cfcdb56502dd91fc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "preprocess the data",
   "id": "e35c1cd86d2f4627"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T01:47:50.170912Z",
     "start_time": "2024-07-14T01:47:50.166084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_function(data_p):\n",
    "    prefix = \"complete: \"\n",
    "    max_length = 512\n",
    "    inputs = [prefix + d for d in data_p['input']]\n",
    "    targets = [d for d in data_p['output']]\n",
    "    model_input = tokenizer(inputs, max_length=max_length, padding=\"max_length\", truncation=True)\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_length, padding=\"max_length\", truncation=True)\n",
    "        \n",
    "    model_input['labels'] = labels['input_ids']  \n",
    "    return model_input"
   ],
   "id": "4956a905208daf26",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T01:47:51.044104Z",
     "start_time": "2024-07-14T01:47:50.793994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trained_data = train_dataset.map(preprocess_function, batched=True)\n",
    "validation_data = validation_dataset.map(preprocess_function, batched=True)\n",
    "test_data = test_dataset.map(preprocess_function, batched=True)"
   ],
   "id": "924e7d00b0a2330d",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T01:47:51.297444Z",
     "start_time": "2024-07-14T01:47:51.294083Z"
    }
   },
   "cell_type": "code",
   "source": "type(validation_data)",
   "id": "668c5748d093d927",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "training arguments",
   "id": "fb49d653b28a3e68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T01:49:56.454084Z",
     "start_time": "2024-07-14T01:49:56.395387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 16\n",
    "epochs = 5\n",
    "max_length = 512\n",
    "output_dir = 't5_data/results'\n",
    "logs_dir = 't5_data/logs'\n",
    "\n",
    "\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    evaluation_strategy='steps',\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    learning_rate=3e-5,\n",
    "    num_train_epochs=epochs,\n",
    "    logging_dir=logs_dir,\n",
    "    eval_steps=1,\n",
    "    logging_steps=200,\n",
    "    save_steps=200,\n",
    "    save_strategy=\"steps\",\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    "    predict_with_generate=True,\n",
    "    warmup_steps=500\n",
    ")"
   ],
   "id": "ad5e5606fa8bc4e2",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "computing the metrics",
   "id": "e0fe5e95fe6ba287"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T02:10:36.138857Z",
     "start_time": "2024-07-14T02:10:34.905164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "perplexity = load(\"perplexity\", module_type=\"metric\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    return perplexity.compute(predictions=decoded_preds, model_id='t5-base')\n",
    "    "
   ],
   "id": "1e8b7e774efd9d2e",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T02:16:29.814156Z",
     "start_time": "2024-07-14T02:16:29.809759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def compute_metrics2(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    \n",
    "    # For T5, we need to handle the shifted labels\n",
    "    shifted_logits = logits[..., :-1, :]\n",
    "    labels = labels[..., 1:]\n",
    "    \n",
    "    # Flatten the tensors\n",
    "    shifted_logits = shifted_logits.reshape(-1, shifted_logits.shape[-1])\n",
    "    labels = labels.reshape(-1)\n",
    "    \n",
    "    # Compute softmax probabilities\n",
    "    probabilities = softmax(shifted_logits, axis=-1)\n",
    "    \n",
    "    # Compute log loss (cross-entropy)\n",
    "    loss = log_loss(labels, probabilities, labels=range(shifted_logits.shape[-1]))\n",
    "    \n",
    "    # Compute perplexity\n",
    "    perplexity = np.exp(loss)\n",
    "    \n",
    "    return {\"perplexity\": perplexity}"
   ],
   "id": "2b220cf9ab105134",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T02:15:29.716351Z",
     "start_time": "2024-07-14T02:15:29.705401Z"
    }
   },
   "cell_type": "code",
   "source": "validation_data.select([0,1])",
   "id": "a388d82446d067d9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The trainer",
   "id": "28b7701b83a442e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T02:16:34.551075Z",
     "start_time": "2024-07-14T02:16:34.540557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset= trained_data.select([0,1]),\n",
    "    eval_dataset= validation_data.select([0,1]),\n",
    "    #compute_metrics=compute_metrics\n",
    ")"
   ],
   "id": "254f44b871964903",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "GPU",
   "id": "933c3baa7d75bc5a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3eebc8e608fcd685"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T02:15:32.584922Z",
     "start_time": "2024-07-14T02:15:32.575467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)"
   ],
   "id": "914474bc8c4d76db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train the model",
   "id": "38d991cdf7145a3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T02:16:41.142169Z",
     "start_time": "2024-07-14T02:16:39.600322Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "47473d537caa3dd5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/5 : < :, Epoch 1/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 1022]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[114], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\LLM\\Lib\\site-packages\\transformers\\trainer.py:1539\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1537\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1539\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inner_training_loop(\n\u001B[0;32m   1540\u001B[0m         args\u001B[38;5;241m=\u001B[39margs,\n\u001B[0;32m   1541\u001B[0m         resume_from_checkpoint\u001B[38;5;241m=\u001B[39mresume_from_checkpoint,\n\u001B[0;32m   1542\u001B[0m         trial\u001B[38;5;241m=\u001B[39mtrial,\n\u001B[0;32m   1543\u001B[0m         ignore_keys_for_eval\u001B[38;5;241m=\u001B[39mignore_keys_for_eval,\n\u001B[0;32m   1544\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\LLM\\Lib\\site-packages\\transformers\\trainer.py:1929\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   1926\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mepoch \u001B[38;5;241m=\u001B[39m epoch \u001B[38;5;241m+\u001B[39m (step \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m steps_skipped) \u001B[38;5;241m/\u001B[39m steps_in_epoch\n\u001B[0;32m   1927\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_end(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[1;32m-> 1929\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001B[0;32m   1930\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1931\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_substep_end(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\LLM\\Lib\\site-packages\\transformers\\trainer.py:2291\u001B[0m, in \u001B[0;36mTrainer._maybe_log_save_evaluate\u001B[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2289\u001B[0m metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   2290\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol\u001B[38;5;241m.\u001B[39mshould_evaluate:\n\u001B[1;32m-> 2291\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluate(ignore_keys\u001B[38;5;241m=\u001B[39mignore_keys_for_eval)\n\u001B[0;32m   2292\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_report_to_hp_search(trial, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step, metrics)\n\u001B[0;32m   2294\u001B[0m     \u001B[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\LLM\\Lib\\site-packages\\transformers\\trainer_seq2seq.py:166\u001B[0m, in \u001B[0;36mSeq2SeqTrainer.evaluate\u001B[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001B[0m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgather_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39mgather\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gen_kwargs \u001B[38;5;241m=\u001B[39m gen_kwargs\n\u001B[1;32m--> 166\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mevaluate(eval_dataset, ignore_keys\u001B[38;5;241m=\u001B[39mignore_keys, metric_key_prefix\u001B[38;5;241m=\u001B[39mmetric_key_prefix)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\LLM\\Lib\\site-packages\\transformers\\trainer.py:3095\u001B[0m, in \u001B[0;36mTrainer.evaluate\u001B[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[0;32m   3092\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m   3094\u001B[0m eval_loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39muse_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_loop\n\u001B[1;32m-> 3095\u001B[0m output \u001B[38;5;241m=\u001B[39m eval_loop(\n\u001B[0;32m   3096\u001B[0m     eval_dataloader,\n\u001B[0;32m   3097\u001B[0m     description\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEvaluation\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   3098\u001B[0m     \u001B[38;5;66;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001B[39;00m\n\u001B[0;32m   3099\u001B[0m     \u001B[38;5;66;03m# self.args.prediction_loss_only\u001B[39;00m\n\u001B[0;32m   3100\u001B[0m     prediction_loss_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_metrics \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   3101\u001B[0m     ignore_keys\u001B[38;5;241m=\u001B[39mignore_keys,\n\u001B[0;32m   3102\u001B[0m     metric_key_prefix\u001B[38;5;241m=\u001B[39mmetric_key_prefix,\n\u001B[0;32m   3103\u001B[0m )\n\u001B[0;32m   3105\u001B[0m total_batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39meval_batch_size \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mworld_size\n\u001B[0;32m   3106\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_jit_compilation_time\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output\u001B[38;5;241m.\u001B[39mmetrics:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\LLM\\Lib\\site-packages\\transformers\\trainer.py:3386\u001B[0m, in \u001B[0;36mTrainer.evaluation_loop\u001B[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[0;32m   3382\u001B[0m         metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_metrics(\n\u001B[0;32m   3383\u001B[0m             EvalPrediction(predictions\u001B[38;5;241m=\u001B[39mall_preds, label_ids\u001B[38;5;241m=\u001B[39mall_labels, inputs\u001B[38;5;241m=\u001B[39mall_inputs)\n\u001B[0;32m   3384\u001B[0m         )\n\u001B[0;32m   3385\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 3386\u001B[0m         metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_metrics(EvalPrediction(predictions\u001B[38;5;241m=\u001B[39mall_preds, label_ids\u001B[38;5;241m=\u001B[39mall_labels))\n\u001B[0;32m   3387\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   3388\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m {}\n",
      "Cell \u001B[1;32mIn[112], line 20\u001B[0m, in \u001B[0;36mcompute_metrics2\u001B[1;34m(eval_preds)\u001B[0m\n\u001B[0;32m     17\u001B[0m probabilities \u001B[38;5;241m=\u001B[39m softmax(shifted_logits, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# Compute log loss (cross-entropy)\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m loss \u001B[38;5;241m=\u001B[39m log_loss(labels, probabilities, labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mrange\u001B[39m(shifted_logits\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]))\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# Compute perplexity\u001B[39;00m\n\u001B[0;32m     23\u001B[0m perplexity \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexp(loss)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\LLM\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\LLM\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2919\u001B[0m, in \u001B[0;36mlog_loss\u001B[1;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001B[0m\n\u001B[0;32m   2908\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2909\u001B[0m     \u001B[38;5;66;03m# TODO: Remove user defined eps in 1.5\u001B[39;00m\n\u001B[0;32m   2910\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   2911\u001B[0m         (\n\u001B[0;32m   2912\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSetting the eps parameter is deprecated and will \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2916\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m   2917\u001B[0m     )\n\u001B[1;32m-> 2919\u001B[0m check_consistent_length(y_pred, y_true, sample_weight)\n\u001B[0;32m   2920\u001B[0m lb \u001B[38;5;241m=\u001B[39m LabelBinarizer()\n\u001B[0;32m   2922\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\LLM\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[1;34m(*arrays)\u001B[0m\n\u001B[0;32m    455\u001B[0m uniques \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(lengths)\n\u001B[0;32m    456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 457\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    458\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    459\u001B[0m         \u001B[38;5;241m%\u001B[39m [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[0;32m    460\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [1, 1022]"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "save model  and tokenizer",
   "id": "593fd50ca7af1ddd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T11:00:44.651543Z",
     "start_time": "2024-07-13T11:00:43.661306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = 't5_data/model'\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ],
   "id": "3ebbaf7b4b5d86c0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t5_data/model\\\\tokenizer_config.json',\n",
       " 't5_data/model\\\\special_tokens_map.json',\n",
       " 't5_data/model\\\\spiece.model',\n",
       " 't5_data/model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "inferencing on test data",
   "id": "b1923b76180ec32b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dcf88ceb872bb49d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
